{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Testing hypotheses\n",
    "\n",
    "Welcome to lab 4!  This lab covers the use of computer simulation, in combination with data, to answer questions about the world.  You'll answer two questions:\n",
    "1. Was a panel of jurors selected at random from the population of eligible jurors?\n",
    "2. Were murder rates in US states from 1960-2003 equally likely to go up or down each year?\n",
    "\n",
    "We'll also learn some basic ways to work with data in tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preliminaries\n",
    "First, run the cell below to prepare the lab and the automatic tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this cell, but please don't change it.\n",
    "\n",
    "# These lines import the NumPy and datascience modules.\n",
    "import numpy as np\n",
    "# This way of importing the datascience module lets you write \"Table\" instead\n",
    "# of \"datascience.Table\".  The \"*\" means \"import everything in the module.\"\n",
    "from datascience import *\n",
    "\n",
    "# These lines set up visualizations.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "# This line loads some special functions for this lab.\n",
    "from lab_utils import *\n",
    "\n",
    "# These lines load the tests.\n",
    "from client.api.assignment import load_assignment \n",
    "lab04 = load_assignment('longlab04.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Jury selection: Swain v. Alabama\n",
    "In lecture, we tested the hypothesis that a jury panel in Alameda County was a random sample from the population of Alameda.  First we'll go through a similar example.\n",
    "\n",
    "##### Background\n",
    "Swain v. Alabama was a US Supreme Court case decided in 1965.  A black man, Swain, was accused of raping a white woman, and had been convicted by an all-white jury.  The jury was selected from a panel that contained only 8 black people and 92 whites.  The panel was supposed to be a random sample from the eligible population of Talladega County, which was 26% black.  Swain's lawyers argued that this reflected a bias in the jury panel selection process.  A five-justice majority of the Supreme Court disagreed, concluding that,\n",
    "\n",
    "> \"The overall percentage disparity has been small and reflects no studied attempt to include or exclude a specified number of Negros.\"\n",
    "\n",
    "Is 8 is enough smaller than 26 to indicate bias?  This may seem like a judgement call.  Apparently five Supreme Court justices thought so (interpreting their motives charitably)!\n",
    "\n",
    "But in fact we can contradict the assertion in the Supreme Court opinion with basic computer simulation.  (The scarcity of computers at the time was no excuse.  Any statistician could have done this calculation by hand in 1965.)\n",
    "\n",
    "Here are the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jury = Table.read_table(\"jury.csv\")\n",
    "jury.barh('Race', [1, 3])\n",
    "jury"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine drawing a random sample from the population of Talladega.  Each person sampled has a 26% chance of being black.  We can simulate drawing 1 person in this way by calling this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_random_sample = random_sample_counts(jury, \"Proportion eligible\", 1)\n",
    "one_random_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table is the same as `jury`, but the last column in this table contains the numbers of Black and Other people in a random sample of 1 person.  The race of the person was decided randomly: they had a 26% chance of being black.\n",
    "\n",
    "If we repeated this many times, about 26% of the time we'd get a black person.  That's the law of averages.  Let's try that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Simulates many samples of sample_size people from the eligible\n",
    "# population.  Prints out some information about the samples we\n",
    "# simulated.\n",
    "def simulate_samples(sample_size):\n",
    "    # We can define a function just for use inside another function!\n",
    "    # This function simulates a sample of people from the eligible\n",
    "    # population and returns the number of black people in that\n",
    "    # sample.\n",
    "    def simulated_num_black():\n",
    "        return random_sample_counts(jury, \"Proportion eligible\", sample_size).column(\"Count in Random Sample\").item(0)\n",
    "\n",
    "    num_simulations = 10000\n",
    "    many_simulations = repeat(simulated_num_black, num_simulations)\n",
    "    simulations_table = Table().with_column(\"number of black people in a sample of \" + str(sample_size), many_simulations)\n",
    "    if sample_size <= 5:\n",
    "        bins = np.arange(-.5, sample_size + .5, .01)\n",
    "    else:\n",
    "        bins = np.linspace(0, sample_size+1, 100)\n",
    "    simulations_table.hist(bins=bins)\n",
    "\n",
    "simulate_samples(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each sample, there was only 1 person, so there could be only 0 or 1 black people.  The histogram shows that around 26% of the time there was 1 black person and 74% of the time there were no black people.\n",
    "\n",
    "Now let's try this with a sample of 100 people.  This is how the jury panel in Swain's case was *supposed* to be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panel_size = 100\n",
    "simulate_samples(panel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram shows the number of black people we expect to see in a sample of 100 from the eligible population.  Sometimes it's as low as 10 or as high as 45.  It's almost never as low as 8.  It might help to draw 8 on the histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot a vertical red line at spot.  You don't need to\n",
    "# read this function unless you're interested.\n",
    "def draw_red_line(spot, height, description):\n",
    "    plt.plot([spot, spot], [0, height], color=\"red\", label=description)\n",
    "    # Draw a legend off to the right to explain the red line.\n",
    "    plt.legend(loc=\"center left\", bbox_to_anchor=[.8, .5])\n",
    "\n",
    "simulate_samples(panel_size)\n",
    "draw_red_line(8, .1, \"number of black people in\\nSwain's jury panel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've demonstrated by simulation that it's extremely unlikely to see a jury panel with only 8 black people, if the panel is really randomly selected from an eligible population with 26% black people.\n",
    "\n",
    "The Supreme Court opinion was factually incorrect; there is strong evidence of some kind of bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Understanding violent crime\n",
    "Does instituting a death penalty for murder have a deterrent effect on murder?  Social scientists have been bringing data to bear on this question for at least 40 years, but the answer is still controversial.  This is in part because the evidence is surprisingly complex.  The final project in the Spring 2016 course had students investigate the evidence.\n",
    "\n",
    "We'll look at a small part of that project, using simulation to answer a preliminary question about the overall trend in murder rates in the US.\n",
    "\n",
    "Our data source for this section comes from a [paper](http://cjlf.org/deathpenalty/DezRubShepDeterFinal.pdf) by three researchers, Dezhbakhsh, Rubin, and Shepherd.  The dataset contains per-capita rates of various violent crimes for every year 1960-2003 (44 years) in every US state.  (Actually, the rates are per 100,000 people.)  The researchers compiled their data from the FBI's Uniform Crime Reports.\n",
    "\n",
    "The dataset is in a file in your account called `crime_rates.csv`.  Run the next cell to load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "murder_rates = Table.read_table('crime_rates.csv').select(['State', 'Year', 'Population', 'Murder Rate'])\n",
    "murder_rates.set_format(2, NumberFormatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1. A basic question\n",
    "Here is one basic question about this dataset:\n",
    "\n",
    "> Across each 2-year period in each state, did murder rates increase more often than they decreased?\n",
    "\n",
    "Let's define the *net number of increases* as the number of times the murder rate increased year-over-year in a state, minus the number of times it decreased.  So we can rephrase our question as: Is the net number of increases positive?\n",
    "\n",
    "This is a question about the data at hand, involving no randomness or unknowns.  We can just compute the answer with Python.\n",
    "\n",
    "First, we define a function that takes an array of murder rates for a single state, in order by year, and produces the number of net increases for that state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rates should be an array of murder rates for a single state,\n",
    "# in order by year.  This function computes the number of\n",
    "# increases over each 2-year period minus the number of\n",
    "# decreases over each 2-year period.\n",
    "def two_year_increases(rates):\n",
    "    # Don't worry about how this is computed; it uses some\n",
    "    # programming ideas we haven't covered.\n",
    "    two_year_diffs = rates[1:] - rates[:-1]\n",
    "    return np.count_nonzero(two_year_diffs > 0) - np.count_nonzero(two_year_diffs < 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to do this for each state.  More precisely, here is a recipe for computing the total number of net increases in US states over this time period:\n",
    "1. take the murder rates for each state,\n",
    "2. put them in an array (50 arrays total),\n",
    "3. call `two_year_increases` on each array (50 calls to `two_year_increases`), and\n",
    "4. sum up all those to get the total net increases in the US over the period.\n",
    "\n",
    "We could do this manually, using a method called `where` that you'll learn about soon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alabama_increases = two_year_increases(murder_rates.where(\"State\", are.equal_to(\"Alabama\")).column(\"Murder Rate\"))\n",
    "alaska_increases = two_year_increases(murder_rates.where(\"State\", are.equal_to(\"Alaska\")).column(\"Murder Rate\"))\n",
    "...\n",
    "manual_total_net_increases = alabama_increases + alaska_increases + ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that would involve writing 50 lines of nearly-identical code!  In computer programming, it's rarely correct to do that kind of repetitive work.\n",
    "\n",
    "<img src=\"https://qph.is.quoracdn.net/main-qimg-3289068633a342369f8e9319609f5762?convert_to_webp=true\"/>\n",
    "\n",
    "Instead, we can have Python do the work for us, using a method called `group`.  Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, make a table with just the State and Murder Rate columns,\n",
    "# for simplicity.\n",
    "state_and_murder_rate = murder_rates.select([\"State\", \"Murder Rate\"])\n",
    "\n",
    "# Group together the 44 years for each state, then compute the\n",
    "# number of net increases for each state.  You'll learn how\n",
    "# to use the group method later.\n",
    "net_increase_count_by_state = state_and_murder_rate.group(\"State\", two_year_increases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Interlude: `group`\n",
    "`group` categorizes rows in a table according to one column (like the State), and then does something with the data in each category.  Let's see some simpler examples.\n",
    "\n",
    "One thing `group` can do with each category is count the number of things in the category.  So we could use `group` to see how many years are covered in our `murder_rates` table for each state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "murder_rates.group(\"State\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each row in the table you see, the `count` column is the number of rows in `murder_rates` with that `State`.  You can see that we have 44 rows for each state.  That's one for each year (1960 to 2003.)\n",
    "\n",
    "**Question 2.1.1.1.** Suppose we want to know how many states are in our dataset for each year.  Make an appropriate table using `group`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_states_by_year = ...\n",
    "num_states_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = lab04.grade(\"q2111\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our hypothesis test, we want to compute the net number of increases in murder rate for each state instead of its count.  It's also possible to do that kind of thing with `group`.  For example, we can compute the highest one-year murder rate in each state over the period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pare down our table to just the State and Murder Rate columns.\n",
    "state_and_murder_rate = murder_rates.select([\"State\", \"Murder Rate\"])\n",
    "\n",
    "highest_murder_rate = state_and_murder_rate.group(\"State\", max)\n",
    "highest_murder_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`group` puts each state's murder rates in its own array, and then calls `max` on each one to produce the maximum murder rate for that state.  Pictorially, if the original table looked like this:\n",
    "\n",
    "|State|Murder Rate|\n",
    "|-|-|\n",
    "|Alabama|8.1|\n",
    "|Alabama|9.5|\n",
    "|Alaska|7.5|\n",
    "|Alaska|8.6|\n",
    "|Alaska|8.2||\n",
    "\n",
    "Then the grouped table is computed like this:\n",
    "\n",
    "|State|Murder Rate max|\n",
    "|-|-|\n",
    "|Alabama|max([8.1, 9.5])|\n",
    "|Alaska|max([7.5, 8.6, 8.2])||\n",
    "\n",
    "...which would result in `state_and_murder_rate.group(\"State\", max)` looking like this:\n",
    "\n",
    "|State|Murder Rate max|\n",
    "|-|-|\n",
    "|Alabama|9.5|\n",
    "|Alaska|8.6||\n",
    "\n",
    "**Question 2.1.1.2.** Use the `murder_rates` table to compute the total US population in each year.  The total US population in a year is just the sum of the populations of the 50 states in that year.  Run the tests for a hint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For your convenience, here's a table with only the Year and Population columns:\n",
    "year_and_population = murder_rates.select([\"Year\", \"Population\"])\n",
    "\n",
    "# Fill in this line.  Use something like:\n",
    "#   year_and_population.group(...).\n",
    "total_pop_by_year = ...\n",
    "\n",
    "# We can use your table to make a plot of US population over time.\n",
    "# You don't need to edit this part.\n",
    "total_pop_by_year.plot(0, 1)\n",
    "total_pop_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = lab04.test(\"q2112\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is what we did to compute the net increases by state:\n",
    "\n",
    "    net_increase_count_by_state = state_and_murder_rate.group(\"State\", two_year_increases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Back to murder rates\n",
    "Now we have the net increases for each state, we just add them up.  The function `np.sum` adds up the elements in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add together the net increases for all the states to get\n",
    "# a single number.\n",
    "total_net_increases = np.sum(net_increase_count_by_state.column(1))\n",
    "\n",
    "print('Total increases minus total decreases, across all states and years:', total_net_increases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so the murder rate increased more often than it decreased.  But does this really say anything interesting about the underlying process according to which murder rates change?\n",
    "\n",
    "Maybe this result is actually compatible with a simple story:\n",
    "\n",
    "> Murder rates *randomly* go up or down each year in each state, like the flip of a coin.\n",
    "\n",
    "Intuitively, we're unlikely to see a lot more increases than decreases if this story is true.  But it's hard to know whether 36 qualifies as \"a lot.\"  We'll use simulation to find out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Simulation\n",
    "Translating into technical language, the simple story is our *null hypothesis*.  We need to simulate what would happen if that hypothesis were true, and see if we'd be surprised to see 36 net increases.  If our data would be surprising under the null hypothesis, that would be evidence against the null hypothesis.\n",
    "\n",
    "The number of net increases is called our *test statistic*.  It's a simple one-number summary of our data that we'll use to check whether our data are likely under the null hypothesis.\n",
    "\n",
    "The null hypothesis says that changes are generated randomly.  So in that story, in each state, each year the murder rate goes up with chance 1/2 and down with chance 1/2.  There are 50 states and 43 2-year periods, so there are $50 \\times 43$ ($2150$) separate chances for a change.\n",
    "\n",
    "Let's simulate them and count the number of net increases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simulate_net_increases():\n",
    "    # First we make a table that gives the chances of each outcome:\n",
    "    # 1/2 for an increase, and 1/2 for a decrease.\n",
    "    changes_distribution = Table().with_column(\"change\",      [\"increase\", \"decrease\"])\\\n",
    "                                  .with_column(\"probability\", [1/2,        1/2])\n",
    "    \n",
    "    # Now we sample 2150 times from that distribution, using the\n",
    "    # built-in method sample_from_distribution.  This results in\n",
    "    # a table that tells us how many times (out of the 2150 simulated\n",
    "    # periods) we saw an increase, and how many times we saw a\n",
    "    # decrease.\n",
    "    num_periods = 50*43\n",
    "    simulated_changes = changes_distribution.sample_from_distribution(\"probability\", num_periods)\n",
    "    \n",
    "    # You can uncomment the next line (remove the # sign) and run\n",
    "    # this cell to see what the simulated_changes table looks like.\n",
    "    #simulated_changes.show()\n",
    "    \n",
    "    # We extract the number of increases and the number of decreases\n",
    "    # and subtract one from the other.\n",
    "    num_increases_in_simulation = simulated_changes.column(\"probability sample\").item(0)\n",
    "    num_decreases_in_simulation = simulated_changes.column(\"probability sample\").item(1)\n",
    "    return num_increases_in_simulation - num_decreases_in_simulation\n",
    "\n",
    "# This is a little magic to make sure that you see the same results\n",
    "# we did, just for pedagogical purposes.\n",
    "np.random.seed(1234567)\n",
    "\n",
    "# Simulate once:\n",
    "one_simulation_result = simulate_net_increases()\n",
    "\n",
    "print(\"In one simulation, there were\", one_simulation_result, \"net increases (versus\", total_net_increases, \"in the real data).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the simulation, we happened to see about as many net increases (30) as we did in the real data (36).  This implies the real data are consistent with the simple story, where change was random.\n",
    "\n",
    "But maybe we just got lucky.  Instead of simulating once, we should simulate many times, and see how the simulations *typically* come out.  Then we can reject our null hypothesis if the number of net increases in the real murder rate data looks really unusual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_simulations = 5000\n",
    "\n",
    "# An array of 5000 net increases, each from a separate simulation\n",
    "# where the changes in murder rates where random.\n",
    "simulated_net_increases = repeat(simulate_net_increases, num_simulations)\n",
    "\n",
    "# Here we've written a function to make a histogram of the\n",
    "# simulated net increases.\n",
    "increases_bins=np.arange(-200, 200, 10)\n",
    "def display_test(null_statistics, actual_statistic):\n",
    "    # Generate a histogram of the simulated net increases.\n",
    "    Table().with_column(\"null test statistics\", null_statistics).hist(bins=increases_bins)\n",
    "    # This function was defined earlier in the lab.  It draws\n",
    "    # a vertical red line at a spot.\n",
    "    draw_red_line(actual_statistic, .01, \"what we actually observed\")\n",
    "\n",
    "# Call the function we defined to actually draw the plot.\n",
    "display_test(simulated_net_increases, total_net_increases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that it wasn't a fluke: 36 net increases in murder rates over 2150 periods is quite consistent with the simple random story.  We shouldn't reject our null hypothesis.\n",
    "\n",
    "If you prefer to be more quantitative, we can compute a P-value.  That's the proportion of simulated results that are at least as \"extreme\" as 36.  Graphically, it's the proportion of stuff in the magenta regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Overlays a histogram for the values in null_statistics\n",
    "# that are larger in magnitude than actual_statistic.\n",
    "# You don't need to read this unless you want to; it's\n",
    "# a little complicated.\n",
    "def display_extreme_region(null_statistics, actual_statistic):\n",
    "    # Identify the simulated net increases that are \"extreme\".\n",
    "    extreme_null_statistics = Table().with_column(\"null stats\", null_statistics).where(0, are.not_between_or_equal_to(-abs(actual_statistic), abs(actual_statistic))).column(0)\n",
    "    # Make a magenta-colored histogram of just those extreme values.\n",
    "    # The tricky bit here is rescaling the height of the histogram\n",
    "    # to match up with the height of our blue histogram.\n",
    "    bin_width = increases_bins.item(1) - increases_bins.item(0)\n",
    "    plt.hist(extreme_null_statistics, bins=increases_bins, weights=[1/(len(null_statistics)*bin_width)]*len(extreme_null_statistics), color=\"magenta\", label=\"random results more extreme\\nthan what we observed\")\n",
    "    plt.legend(loc=\"center left\", bbox_to_anchor=[.8, .5])\n",
    "\n",
    "# We plot the actual histogram again...\n",
    "display_test(simulated_net_increases, total_net_increases)\n",
    "# ...and then this call overlays the extreme region on it.\n",
    "display_extreme_region(simulated_net_increases, total_net_increases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually compute this proportion, we can put our simulated net increases in a table and use a method called `where` to find how many are bigger than the observed net increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First we take our array of simulated net increases and make them\n",
    "# a column of a table with only one column.  That way we can use\n",
    "# the useful table functions to filter them.\n",
    "simulation_table = Table().with_column(\"simulated net increases\", simulated_net_increases)\n",
    "\n",
    "# Now we find the rows where the simulated net increases weren't\n",
    "# between -36 and 36.\n",
    "more_extreme = simulation_table.where(\"simulated net increases\", are.not_between_or_equal_to(-abs(total_net_increases), abs(total_net_increases)))\n",
    "\n",
    "# The P-value is the number of times the simulated increases\n",
    "# weren't between -36 and 36, divided by the total number of\n",
    "# simulations we ran.\n",
    "p_value = more_extreme.num_rows / simulation_table.num_rows\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you get the hang of this, you won't need to visualize the sampling distribution and observed test statistic as we did.  Then you'd only need to write the code in this last cell to compute a P-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Interlude: `where`\n",
    "To find the simulations where the net increases were extreme, we used `where`.  This kind of operation is also called \"filtering.\"  Like `group`, it's an important part of the data analysis toolbox.  Let's spend some time to understand it.\n",
    "\n",
    "##### Filtering by state\n",
    "Suppose we want to see only the murder rate data from California.  We can use `where` to do that.  Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "murder_rates.where(\"State\", are.equal_to(\"California\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`where` takes 2 arguments:\n",
    "1. The name of the column that contains the data you want to filter by.  In this case, we want the rows where the state has a certain name, so we use the name of the State column.\n",
    "2. A \"predicate\" that tells it whether to accept or reject values in that column.  Predicates are a bit magical, but they're simple to use if you don't think about how they work.  They're all created by calling functions in a module called `are`.  In this case, we want rows where the State column's value is `\"California\"`.\n",
    "\n",
    "It returns a table containing only the subset of the rows in the original table where the predicate matches the value in the named column.\n",
    "\n",
    "It's helpful to translate code like this into English in your head.  In this case, think:\n",
    "\n",
    "> \"the rows in murder rates where the State is California\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.1.1.** Make a table of the data from the year 1960."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "murder_rates_1960 = ...\n",
    "murder_rates_1960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = lab04.grade(\"q2211\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtering multiple years with `where`\n",
    "Suppose we want only the data from the years 1971 to 1973.  We can use `where` again, with a different predicate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "murder_rates.where(\"Year\", are.between_or_equal_to(1971, 1973))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you type\n",
    "\n",
    "    are.\n",
    "\n",
    "in a code cell and hit Tab, you'll see a full list of the available predicates.  They have pretty straightforward names.\n",
    "\n",
    "**Question 2.2.1.2.** Make a table like `murder_rates`, but containing only the rows for state-years when murder rates were above 16.5 per 100,000 per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_murder_rates = ...\n",
    "high_murder_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = lab04.grade(\"q2212\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to compute the P-value in our test, we used `where` to select the simulation results that were bigger in magnitude than 36, the actual number of net increases:\n",
    "\n",
    "    simulation_table.where(\n",
    "        \"simulated net increases\",\n",
    "        are.not_between_or_equal_to(-abs(total_net_increases), abs(total_net_increases)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Interpretation\n",
    "There is a long tradition of declaring that we can reject a null hypothesis with \"statistical significance\" if our P-value is less than 0.05, and with \"high statistical significance\" if it is less than 0.01.  These thresholds are historical accidents.\n",
    "\n",
    "It's better to think of the P-value as measuring the strength of the evidence in favor of the null hypothesis.  Low values indicate that the evidence goes against the null hypothesis and in favor of some alternative model of the world.\n",
    "\n",
    "If you must use a threshold and come to a yes-or-no conclusion, come up with your own threshold by considering how much evidence you'd need to reject the null hypothesis.\n",
    "\n",
    "In this case, the null hypothesis seems somewhat implausible to begin with.  Why would changes in murder rates behave in such a simple way?  So we might be comfortable \"rejecting\" it if we found a P-value of, say, 0.02.  But, in fact, the data are quite consistent with the null hypothesis.\n",
    "\n",
    "**Question 2.3.1.** Here are some potential conclusions we could draw from this mathematical exercise.  Which ones are valid?  Discuss with a neighbor.\n",
    "\n",
    "1. The fact that there were 36 more increases than decreases in murder rates is not strong evidence against the hypothesis that murder rates were equally likely to go up or down.\n",
    "2. The changes in murder rates over this period were probably random.\n",
    "3. There is no discernable pattern in the changes in murder rates over this period.\n",
    "4. There were as many increases as decreases in the murder rate over this period.\n",
    "5. There were more increases than decreases in the murder rate over this period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

