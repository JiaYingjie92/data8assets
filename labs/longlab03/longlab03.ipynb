{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Sampling and visualizations\n",
    "\n",
    "Welcome to lab 3!  We're going to take a breather from learning Python and focus on some basic things we can do with tables.  In this lab:\n",
    "1. We'll see several ways to make visualizations.\n",
    "2. We'll use tables to simulate random sampling.\n",
    "3. We'll use histograms to visualize the results of sampling.\n",
    "\n",
    "The cell below imports the packages we'll use so you don't have to worry about it later.  It also takes a few lines to set up visualizations in Jupyter notebooks.  Run it before you continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this cell, but please don't change it.\n",
    "\n",
    "# These lines import the NumPy, datascience, and math modules.\n",
    "import numpy as np\n",
    "# This way of importing the datascience module lets you write \"Table\" instead\n",
    "# of \"datascience.Table\".  The \"*\" means \"import everything in the module.\"\n",
    "from datascience import *\n",
    "import math\n",
    "\n",
    "# These lines set up visualizations.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "# These lines load the tests.\n",
    "from client.api.assignment import load_assignment \n",
    "lab03 = load_assignment('longlab03.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Visualizations\n",
    "In the previous lab, we worked with data on world population.  Here we've loaded it again into a table, now with US population for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population = Table.read_table(\"population.csv\")\n",
    "population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Line plots\n",
    "Suppose we want to see how world population has changed over time.  We could read the data in the table (calling `population.show()` will show the entire table), but that's a pretty bad way of looking at numbers.  Instead, let's make a line plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population.plot(\"Year\", \"World Population\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument to `plot` is the name of the column with the x-axis data, and the second is the name of the column with the y-axis data.\n",
    "\n",
    "We can also plot US and world population together.  When we omit the second argument to `plot`, it makes a separate curve with y-axis data from each column other than \"Year\".  Since the two other columns in our table are \"World Population\" and \"US Population\", this plots both the world and US population on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population.plot(\"Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, it's hard to compare them on this scale.  This is a common problem with visualizations.  We could try comparing their orders of magnitude instead.\n",
    "\n",
    "To do that, we'll make a new table with the orders of magnitude.  We'll use `np.log10` on the US and world population columns (which are just arrays), like we did in the previous lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It's possible to substantially shorten the code we've written\n",
    "# here, and later we will use those shortened forms.  For now we've\n",
    "# written it in a fairly verbose way, for clarity.\n",
    "\n",
    "# Start with an empty table, produced by calling Table().\n",
    "# The idea is that we'll grow it with each column we want it to have.\n",
    "empty = Table()\n",
    "\n",
    "# Extend that table with the column of years.\n",
    "with_years = empty.with_column(\"Year\", population.column(\"Year\"))\n",
    "\n",
    "# Compute the log US populations.  This is an array of\n",
    "# numbers, each the logarithm of the US population in\n",
    "# a different year.\n",
    "log_us_population = np.log10(population.column(\"US Population\"))\n",
    "\n",
    "# Extend our table with a column of log US populations.\n",
    "with_us = with_years.with_column(\"US Population (log)\", log_us_population)\n",
    "\n",
    "# Compute the log world populations.\n",
    "log_world_population = np.log10(population.column(\"World Population\"))\n",
    "\n",
    "# Extend our table one last time with a column of log\n",
    "# world populations.\n",
    "magnitudes = with_us.with_column(\"World Population (log)\", log_world_population)\n",
    "\n",
    "# Now we can make our plot.\n",
    "magnitudes.plot(\"Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The US line is slightly less steep than the world line, so the US population has been growing a bit more slowly than the world population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Scatter plots\n",
    "Now let's look at the IMDb movie dataset.  This dataset includes a few hundred highly-rated movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imdb = Table.read_table(\"imdb_ratings.csv\")\n",
    "imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to see if there's a relationship between the number of votes movies receive and their age, at least among these high-quality movies.  We might hypothesize that older movies receive fewer votes, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imdb.scatter(\"Year\", \"Votes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like older movies indeed tend to receive fewer votes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.1.** Make a scatter plot to compare the year a movie came out and the *decade* in which it came out.  Before you draw the plot, see if you can predict what the plot will look like, assuming we've computed the decades correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Histograms\n",
    "From the first scatter plot we drew, we might get some sense of how many movies from each time period are in our dataset.  There are more dots in the later periods than the earlier ones.  But a *histogram* is a much more helpful for this kind of question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imdb.hist(\"Year\", unit=\"year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument to `hist` is the name of the column containing the data we want to display.  The `unit=\"year\"` part tells the plot to say \"Percent per **year**\" on the y-axis.  It's called a *named argument* because we write the name of the argument, `unit` in addition to the argument itself, which is `\"year\"`.  Some functions work this way because it's more clear what the argument does.\n",
    "\n",
    "`hist` puts the data into \"bins,\" and each bar represents the data in one bin.  For example, the third bar from the left bar covers the years from 1940 to 1949.  It has height around 0.6 and width 9 (1940-1949), so its area is around 5.4.  That means 5.4% of the movies are from 1940 to 1949.\n",
    "\n",
    "`hist` chose bins of width 9 rather than 10, which is a little weird.  We can override the default by passing an array of numbers to `hist`, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "every_decade = np.arange(1920, 2030, 10)\n",
    "imdb.hist(\"Year\", unit=\"year\", bins=every_decade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bins are a little confusing, and the defaults are often okay, so we won't dwell on them too much.\n",
    "\n",
    "**Question 1.3.1.** Make a histogram of the movie ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is a good array to use for bins.\n",
    "every_tenth = np.arange(8.0, 9.4, .1)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sampling\n",
    "Our dataset has information about 250 movies.  Often we don't have access to all the data we want; perhaps we only have a *random sample* of them.\n",
    "\n",
    "For example, maybe IMDb doesn't want to give us all their data.  Instead, they put the names of the movies on 50 cards, shuffle the cards, pick 50 of them, and show us only the movies on those 50 cards.  We call the 250 movies the *population* and the 50 movies a *uniform random sample without replacement* from them.\n",
    "\n",
    "We can simulate this using the method `sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imdb_sample = imdb.sample(50)\n",
    "imdb_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`imdb_sample` is a table like `imdb`, with the same columns.  But only 50 of the original 250 rows remain.  (The table `imdb` is unaffected by this; it still contains all the data.)\n",
    "\n",
    "It is an amazing fact that we can sometimes make strong -- though not airtight -- inferences about the population of movies, using only the sample.  Let's see if that's true here.\n",
    "\n",
    "Suppose we want to know how many movies from each year were in the population.  For reference, here is the population histogram again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imdb.hist(\"Year\", unit=\"year\", bins=every_decade)\n",
    "_ = plt.title(\"Release years in the full dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot a histogram of the movie release years in the sample, here's what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imdb_sample.hist(\"Year\", unit=\"year\", bins=every_decade)\n",
    "_ = plt.title(\"Release years in a random sample of 50 movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably see a histogram that vaguely resembles the population histogram, but it's not a perfect match.  We could answer some coarse questions accurately (like \"are more of the movies from 1980 or later?\"), but individual bin sizes are likely to be a little off.\n",
    "\n",
    "If we use a larger sample, we will usually get something closer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "larger_imdb_sample = imdb.sample(150)\n",
    "larger_imdb_sample.hist(\"Year\", unit=\"year\", bins=every_decade)\n",
    "_ = plt.title(\"Release years in a random sample of 150 movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is not a guarantee.  We might, for example, get unlucky enough to see a sample of the 150 earliest movies.  Rather than wait for that to happen, we'll pretend it did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unlucky_imdb_sample = imdb.sort(\"Year\").take(np.arange(150))\n",
    "unlucky_imdb_sample.hist(\"Year\", unit=\"year\", bins=every_decade)\n",
    "_ = plt.title(\"Release years in an unlucky sample of 150 movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we assumed this was similar to the population, we'd think there were no movies after 2000 in `imdb`.  That would be an incorrect conclusion, of course.\n",
    "\n",
    "When we take a random sample of 150 movies, all possible samples are equally likely, so we're just as likely to see this unlucky sample as `larger_imdb_sample`.  But there are many, many possible samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_possible_samples = math.factorial(250) // (math.factorial(150)*math.factorial(100))\n",
    "num_possible_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of those possible samples of 150 movies produce histograms that are roughly similar to the histogram of movie years in `imdb`.  So if we only had access to a large random sample, not the `imdb` table itself, we could probably make reasonable conclusions from that histogram, subject to a little random error.\n",
    "\n",
    "It wasn't clear a priori that the same of 50 would work poorly and the sample of 150 would work pretty well.  And if we wanted very precise information about the release years in `imdb`, even the sample of 150 might not suffice.  Much of the statistical content of this course is about characterizing, more precisely, the error that arises when we make conclusions from random samples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

