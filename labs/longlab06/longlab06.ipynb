{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6\n",
    "\n",
    "Welcome to lab 6!  In lab 5, we used simulation to investigate the random variation in an estimate that was based on a random sample.  Now we'll flip that idea on its head to make it useful for *statistical inference*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preliminaries\n",
    "\n",
    "As usual, **run the cell below** to prepare the lab and the automatic tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this cell, but please don't change it.\n",
    "\n",
    "# These lines import the NumPy and datascience modules.\n",
    "import numpy as np\n",
    "# This way of importing the datascience module lets you write \"Table\" instead\n",
    "# of \"datascience.Table\".  The \"*\" means \"import everything in the module.\"\n",
    "from datascience import *\n",
    "\n",
    "# These lines set up visualizations.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "# These lines load the tests.\n",
    "from client.api.assignment import load_assignment \n",
    "lab06 = load_assignment('longlab06.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Warplanes again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time, we saw how various estimates of the number of warplanes would typically vary.  Now let's make that more useful by producing *confidence intervals* to quantify our uncertainty in a *given estimate*.\n",
    "\n",
    "Remember the setup: We (the RAF in World War II) want to know the number of warplanes fielded by the Germans.  That's equal to the largest serial number on any of the warplanes.  We only see a small number of serial numbers (assumed to be a random sample from among all the serial numbers), so we have to use estimation.\n",
    "\n",
    "To simulate this, we're going to hide the true number (`N`) from you.  You'll have access only to this random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FIXME: Delete\n",
    "# The biggest serial number.\n",
    "N = 150\n",
    "# The number of observations.\n",
    "num_observations = 17\n",
    "\n",
    "def simulate_observations():\n",
    "    return np.random.randint(1, N+1, num_observations)\n",
    "\n",
    "t = Table().with_column(\"serial number\", simulate_observations())\n",
    "t.to_df().to_csv(\"serial_numbers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "observations = Table.read_table(\"serial_numbers.csv\").column(0)\n",
    "num_observations = len(observations)\n",
    "\n",
    "def plot_serial_numbers(numbers):\n",
    "    Table().with_column(\"serial number\", numbers).hist(bins=np.arange(1, 200))\n",
    "    plt.ylim(0, .25)\n",
    "\n",
    "plot_serial_numbers(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your job is to estimate `N`.  You'll see that a confidence interval will help you understand how sure you should be about your answer.\n",
    "\n",
    "We saw that one way to estimate `N` was to take twice the mean of the serial numbers we see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_based_estimator(nums):\n",
    "    return 2*np.average(nums)\n",
    "\n",
    "mean_based_estimate = mean_based_estimator(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** In this particular sample, what's the biggest number?  Compute it, giving it the name `max_estimate`. Think about what that implies about `mean_based_estimate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_estimate = ...\n",
    "max_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = lab06.grade(\"q11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`N` is surely at least as big as the biggest serial number in our sample.  So in this case, we can tell that the mean-based estimate is off.\n",
    "\n",
    "If we knew the sampling distribution of the mean-based estimate, we'd know how far off it typically is.  Unfortunately, since we don't know `N`, we can't just simulate to compute that sampling distribution.  Remember, our `simulate_observations` function in lab 5 looked like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can't write this part, because we don't know N!\n",
    "N = ...\n",
    "\n",
    "def simulate_observations():\n",
    "    # You'll get an error message if you try to call this\n",
    "    # function.\n",
    "    return np.random.randint(1, N+1, num_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Resampling\n",
    "Instead, we'll use resampling.  That is, instead of sampling from the true distribution of serial numbers, we'll sample from our sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observations_table = Table().with_column(\"serial number\", observations)\n",
    "\n",
    "def simulate_resample():\n",
    "    return observations_table.sample(num_observations, with_replacement=True).column(0)\n",
    "\n",
    "# This is a little magic to make sure that you see the same results\n",
    "# we did.\n",
    "np.random.seed(123)\n",
    "one_resample = simulate_resample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.1.** Make a histogram to display the distribution of serial numbers in `one_resample`.  Use the function `plot_serial_numbers`, which was defined and used a few screens above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_serial_numbers(one_resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare, here's the actual observations again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_serial_numbers(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the resample has only the elements of the sample.  Some are repeated several times, and some don't get into the resample at all.\n",
    "\n",
    "The mean of the resample is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_based_estimator(one_resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat this many times and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_simulations = 20000\n",
    "\n",
    "#FIXME: Put in library\n",
    "def repeat(f, repetitions):\n",
    "    return [f() for i in range(repetitions)]\n",
    "\n",
    "def simulate_estimates(estimator, simulator):\n",
    "    simulations = Table().with_column(\"resample\", repeat(simulator, num_simulations))\n",
    "    return simulations.apply(estimator, \"resample\")\n",
    "\n",
    "bins = np.arange(50, 250, 1)\n",
    "\n",
    "def draw_simulated_distribution(estimator, simulator):\n",
    "    Table().with_column(\"estimates\", simulate_estimates(estimator, simulator)).hist(\"estimates\", bins=bins)\n",
    "\n",
    "draw_simulated_distribution(mean_based_estimator, simulate_resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call this a \"resampling\" or \"bootstrap\" distribution of our estimate.\n",
    "\n",
    "Its interpretation is: If the population looked like our sample, then we'd expect our estimator usually to produce estimates between around 80 and 170, and often between around 100 and 140.  We just looked at the histogram to come up with those numbers.\n",
    "\n",
    "We can be more quantitative about this by computing *percentiles* of the resampling distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resample_estimates = simulate_estimates(mean_based_estimator, simulate_resample)\n",
    "\n",
    "def coverage_interval(numbers, coverage):\n",
    "    return np.percentile(numbers, [(100-coverage)/2, (100+coverage)/2])\n",
    "\n",
    "def print_coverage_interval(numbers, coverage):\n",
    "    interval = coverage_interval(numbers, coverage)\n",
    "    pattern = \"If the population looked like our sample, our sample-based estimates of N would be between {:.2f} and {:.2f} {:.1f}% of the time.\"\n",
    "    message = pattern.format(interval.item(0), interval.item(1), coverage)\n",
    "    print(message)\n",
    "\n",
    "print_coverage_interval(resample_estimates, 95)\n",
    "print_coverage_interval(resample_estimates, 99.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we've written some code to display a resampling distribution with these percentiles overlaid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_distribution_and_interval(estimator, simulator, coverage):\n",
    "    estimates = simulate_estimates(estimator, simulator)\n",
    "    interval = coverage_interval(estimates, coverage)\n",
    "    Table().with_column(\"estimates\", estimates).hist(\"estimates\", bins=bins)\n",
    "    \n",
    "    def draw_bar(x):\n",
    "        plt.plot([x, x], [0, .04], color=\"red\")\n",
    "    \n",
    "    draw_bar(interval.item(0))\n",
    "    draw_bar(interval.item(1))\n",
    "    plt.title(\"{:.2f}% coverage interval\".format(coverage))\n",
    "\n",
    "draw_distribution_and_interval(mean_based_estimator, simulate_resample, 95)\n",
    "draw_distribution_and_interval(mean_based_estimator, simulate_resample, 99.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Confidence Intervals\n",
    "Now comes the tricky part.  We'd like to move from a statement like this:\n",
    "\n",
    "> \"If the population looked like this, then we'd usually get estimates for `N` between A and B.\"\n",
    "\n",
    "...to what we really want:\n",
    "\n",
    "> \"We claim `N` is actually between X and Y, and usually our claims are right.\"\n",
    "\n",
    "We can't cover the intricacies of the idea in full here.  But the idea is to flip our thinking around.  Assume that the *variability* in estimates would look roughly the same for all the plausible values of `N`.  Then if we put an interval around our estimate of `N` that covers 95% of the resamples, it's also true that 95% of the time our estimate will be close enough to `N` that our interval will cover `N`.\n",
    "\n",
    "Anyway, here is the method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Table().with_columns([\"resampling estimates\", resample_estimates, \"estimates (if N were 140)\", resample_estimates - np.mean(resample_estimates) + 140]).hist(bins=bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then 95% of the time, our estimates would still cover 121.8, which is the mean in our actual sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_sample_simulator(simulated_N):\n",
    "    def simulator():\n",
    "        return np.random.randint(1, simulated_N+1, num_observations)\n",
    "    return simulator\n",
    "\n",
    "draw_simulated_distribution(mean_based_estimator, make_sample_simulator(140))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error = N - max_estimate\n",
    "print(\"Our estimate is {} off from N.\".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But maybe we got lucky or unlucky.  If we're deciding whether to use this method for a similar task, we'd like to know how it *typically* performs, not how it happened to perform this time.\n",
    "\n",
    "To see what typically happens, we just run our simulation many times.  The cell below does that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_simulations = 20000\n",
    "bins = np.arange(N - 60 + 1, N + 60 + 1, 1)\n",
    "\n",
    "#FIXME: This should be in a library.\n",
    "def repeat(f, repetitions):\n",
    "    return [f() for i in range(repetitions)]\n",
    "\n",
    "def draw_max_distribution():\n",
    "    simulations = Table().with_column(\"observations\", repeat(simulate_observations, num_simulations))\n",
    "    maxes = simulations.apply(max, \"observations\")\n",
    "    simulations.with_column(\"max\", maxes).hist(\"max\", bins=bins)\n",
    "\n",
    "draw_max_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram says how often we get different estimates of `N` using this technique.  It's a histogram displaying the *probability distribution* of this estimate.  Sometimes that's called, somewhat confusingly, the *sampling distribution* of the estimate.\n",
    "\n",
    "The first thing to notice is that we don't always get the right answer.  You might say that we usually get close to the right answer, but that depends on your definition of \"close.\"  When you're trying to figure out how many warplanes the Germans have, you might want to be even more accurate!\n",
    "\n",
    "You should also find that the sample max is never bigger than `N`, but it's sometimes smaller.  In other words, you only ever *underestimate* `N` using this technique.\n",
    "\n",
    "**Question 1.2.2.** Try to explain this phenomenon in your own words.  Discuss with your neighbor if you're stuck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.  (Double-click this cell to edit it, and click the \"run cell\" button to switch back to display mode.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extrapolating from the average\n",
    "Here's another idea that comes from looking at the probability histogram of the serial numbers.\n",
    "\n",
    "Since the serial numbers are evenly distributed from 1 to `N`, the average of all the serial numbers is roughly in the middle: $\\frac{\\texttt{N}}{2}$.  Further, the law of averages says (heuristically) that the average of a sample is likely to be close to the average of the population it was sampled from.  So if we multiply the average of our observations by 2, we might get something close to `N`.\n",
    "\n",
    "If you prefer symbols, here's another way to say that:\n",
    "\n",
    "$$\\texttt{average}(\\texttt{all serial numbers}) \\approx \\frac{\\texttt{N}}{2} \\\\\n",
    "  \\overset{\\text{by law of averages}}{\\implies} \\texttt{average}(\\texttt{observations}) \\approx \\frac{\\texttt{N}}{2} \\\\\n",
    "  \\implies 2 \\times \\texttt{average}(\\texttt{observations}) \\approx \\texttt{N}$$\n",
    "\n",
    "Here's a function that computes twice the mean of an array of serial numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_based_estimator(nums):\n",
    "    return 2*np.average(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.3.** Use that function to estimate `N` from `observations`.  Call the result `mean_based_estimate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute mean_based_estimate using your simulated observations.\n",
    "mean_based_estimate = ...\n",
    "mean_based_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = lab05.grade('q123')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, it's not clear whether this estimate was about as accurate we'd expect from this method, or just a fluke.  As before, we can see how this estimator works by simulating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_twice_mean_distribution():\n",
    "    simulations = Table().with_column(\"observations\", repeat(simulate_observations, num_simulations))\n",
    "    twice_means = simulations.apply(mean_based_estimator, \"observations\")\n",
    "    simulations.with_column(\"twice means\", twice_means).hist(\"twice means\", bins=bins)\n",
    "\n",
    "draw_twice_mean_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.4.** Among the two estimators we've seen so far, which would you prefer?  Think about the criteria you would use to decide this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice something about the histograms we've seen so far:\n",
    "\n",
    "1. The twice-the-mean estimator has (roughly) a Normal distribution.\n",
    "2. The max estimator doesn't have a Normal distribution.  Classical statistical techniques, which assume sampling distributions are roughly Normal, wouldn't work very well to help us understand how that estimator works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Something more clever\n",
    "So far, it looks like our choice is between an estimator that chronically underestimates our target and one that tends to make large errors.  Let's take a look at the distribution of maxes again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_max_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good question to ask about this histogram is: \"Why can't we just shift the estimates over a bit to get more of them close to 120?\"\n",
    "\n",
    "Another way of thinking about this is that it's unlikely we actually get the biggest serial number in our sample, so it makes sense to guess that the real `N` is something a bit higher than the biggest serial number we observe.  For example, if we see 110, it's probably safe to guess that `N` is 111.\n",
    "\n",
    "Well, we can act on that.  Let's try a few different \"shifted\" estimators -- the max of the sample, plus a bit.  First we'll define some functions to make that easier.  (If you can't follow these, that's okay; there will be a lab session later where you can learn how to use functions like this.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def max_plus_n(n):\n",
    "    def max_func(nums):\n",
    "        return max(nums) + n\n",
    "    return max_func\n",
    "\n",
    "def simulate_estimates(estimator):\n",
    "    simulations = Table().with_column(\"observations\", repeat(simulate_observations, num_simulations))\n",
    "    return simulations.apply(estimator, \"observations\")\n",
    "\n",
    "def draw_sampling_distribution(estimator):\n",
    "    Table().with_column(\"estimates\", simulate_estimates(estimator)).hist(\"estimates\", bins=bins)\n",
    "\n",
    "draw_sampling_distribution(max_plus_n(5))\n",
    "draw_sampling_distribution(max_plus_n(10))\n",
    "draw_sampling_distribution(max_plus_n(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first two, more of the weight of the bars is near 120.  That means we're typically getting closer to 120 this way, which is what we want.  15 goes too far.  So it looks like shifting over by 5 or 10 is a good idea.\n",
    "\n",
    "Why?  Here's an idea pointed out by a student in Data 8 lecture.  Think about what would happen if our samples came out evenly-spaced in the interval 1 to 120.  The space between them would be $\\frac{120}{14}$, or roughly 8.5.  They'd look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_serial_numbers(np.arange(N/num_observations, N, N/num_observations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biggest observation, hence our max estimate, would be around 8.5 less than 120.  So we can correct for this by adding back in $\\frac{120}{14}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adjusted_estimator = max_plus_n(N/num_observations)\n",
    "draw_sampling_distribution(adjusted_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that this is a pretty good way to estimate the number of warplanes.\n",
    "\n",
    "It's worth noting again that the sampling distribution doesn't look very Normal.  Classical statistical methods wouldn't help you understand it, but we can simulate it precisely with a few lines of code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

